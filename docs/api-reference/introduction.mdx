---
title: Introduction
description: "Welcome to the OpenMind API Reference"
---

OpenMind integrates with multiple LLM providers to offer a diverse range of features. This API reference provides details on endpoints, parameters, and responses, enabling efficient interaction with the OpenMind API.

## API Keys

OpenMind requires an API key to authenticate requests. You can obtain an API key by signing up for an account on the [OpenMind portal](https://portal.openmind.org). The API key must be included in the `Authorization` or `x-api-key` header of each request, used to authenticate your requests and track usage quotas.

**Keep your API key confidential**. Never share it with others or expose it in client-side code, such as in browsers or apps.

Remember to include your API key in the `Authorization` or `x-api-key` header of each request. For example:

```bash
x-api-key: YOUR_API_KEY
# or,
Authorization: Bearer YOUR_API_KEY
```

For websocket connections, include the API key in the query string. For example: `wss://api.openmind.org?api_key=<YOUR_API_KEY>`.

## API Pricing

Access our API, scale usage as needed, and stay in control of costs. For detailed API pricing, refer [here](./api_pricing)

- High-speed requests
- Cutting-edge large models
- Integrated modules for multiple robots

For developer walkthrough and support reach out to: support@openmind.org

### LLM Models

| Service                               | Input Price (per 1M tokens) | Output Price (per 1M tokens) |
|---------------------------------------|-----------------------------|------------------------------|
| OpenAI GPT-4o                         | 25000 OMCU                  | 100000 OMCU                  |
| OpenAI GPT-4o-mini                    | 1500 OMCU                   | 6000 OMCU                    |
| OpenAI GPT-4.1                        | 20000 OMCU                  | 80000 OMCU                   |
| OpenAI GPT-4.1-mini                   | 4000 OMCU                   | 16000 OMCU                   |
| OpenAI GPT-4.1-nano                   | 1000 OMCU                   | 4000 OMCU                    |
| OpenAI GPT-5                          | 1250 OMCU                   | 100000 OMCU                  |
| OpenAI GPT-5-mini                     | 2500 OMCU                   | 10000 OMCU                   |
| OpenAI GPT-5-nano                     | 500 OMCU                    | 2000 OMCU                    |
| DeepSeek Chat                         | 1400 OMCU                   | 2800 OMCU                    |
| Gemini 2.5 Flash                      | 3000 OMCU                   | 25000 OMCU                   |
| Gemini 2.5 Flash Lite                 | 1000 OMCU                   | 4000 OMCU                    |
| Gemini 2.5 Pro                        | 25000 OMCU                  | 150K OMCU                    |
| Gemini 3 Pro                          | 40000 OMCU                  | 180K OMCU                    |
| Gemini 3 Flash                        | 10000 OMCU                  | 30K OMCU                     |
| grok-2-latest                         | 20000 OMCU                  | 100000 OMCU                  |
| grok-3-beta                           | 30k OMCU                    | 150k OMCU                    |
| grok-4-latest                         | 30k OMCU                    | 150k OMCU                    |
| grok-4                                | 30k OMCU                    | 150k OMCU                    |
| qwen3-30b-a3b-instruct-2507 (Near AI) | 1500 OMCU                   | 4500 OMCU                    |
| qwen-2.5-7b-instruct (Near AI)        | 400 OMCU                    | 1000 OMCU                    |
| qwen2.5-vl-72b-instruct (Near AI)     | 5900 OMCU                   | 5900 OMCU                    |
| llama-3.1-70b-instruct (Meta Llama)   | 1000 OMCU                   | 2800 OMCU                    |
| llama-3.3-70b-instruct (Meta Llama)   | 9K OMCU                     | 9K OMCU                      |
| anthropic/claude-sonnet-4.5           | 30K OMCU                    | 150K OMCU                    |
| anthropic/claude-opus-4.1             | 150K OMCU                   | 750K OMCU                    |

<Note>
Near AI models are hosted and served by [Near AI](https://cloud.near.ai).
Meta Llama and Anthropic models are hosted and served by [Openrouter](https://openrouter.ai/).
For free local inference, [Ollama](https://ollama.ai) supports models like llama3.2, mistral, and phi3 with no API costs.
</Note>

### TTS Models (Text to Speech)

| Service              | Price (per 1M characters) |
|----------------------|---------------------------|
| Eleven Labs          | 30k OMCU                  |
| Riva                 | 9999 OMCU                 |

We will support more models in the future. Contact us if you have any questions or need a custom solution.

### ASR Models (Speech to Text)

| Service              | Price (per 1 minute) |
|----------------------|----------------------|
| Google ASR           | 51 OMCU              |
